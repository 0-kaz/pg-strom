<article class="manual_1" id="pl_cuda">
<h1>PL/CUDA</h1>
<p>
<span lang="en">
This chapter introduces the way to implement GPU executable native program as SQL functions, using PL/CUDA procedural language.
</span>
<span lang="ja">
本章では、PL/CUDA言語を用いて、GPUで実行可能なネイティブプログラムをSQL関数として実装する方法について説明します。
</span>
</p>

<p>
<div id="caution">
<span lang="en">
A series of discussion to support matrix data type is held in PostgreSQL developers community now.
Please note that the matrix data type provided by the current version of PG-Strom may change its data format in the furture release.
</span>
<span lang="ja">
現在、PostgreSQLコミュニティでは行列型（matrix型）のサポートについて議論が行われています。
現バージョンのPG-Stromが独自に提供する行列型（matrix型）は、将来のバージョンにおいてフォーマットが変更となる可能性がある事に留意してください。
</span>
</div>
</p>

<section class="manual_2" id="plcuda_overview">
<h2>
<span lang="en">PL/CUDA Overview</span>
<span lang="ja">PL/CUDA 概要</span>
</h2>
<p>
<span lang="ja">
PostgreSQLでは、<code>CREATE LANGUAGE</code>構文を用いて、SQL関数の記述に用いるプログラミング言語を追加する事ができます。
</span>
</p>

<p>
<span lang="ja">
内部的に、PG-StromはSQL構文を元にCUDA言語によるGPUプログラムを生成し、これを実行時コンパイルによってGPU用命令バイナリを生成します。CUDAとはNVIDIA社の提供するGPUプログラミング環境で、C言語に似た構文を用いて並列プログラムを記述する事ができます。
</span>
</p>

<p>
<span lang="ja">
PL/CUDAを使用すると、PG-Stromが自動生成するGPUプログラムだけでなく、ユーザが実装した任意のGPUプログラムをSQL関数として実行する事が可能となります。
SQL関数の引数には、数値型やtext型、行列型など、PG-Stromのサポートするデータ型を使用する事ができますが、これらはPL/CUDA実行系が自動的にGPU側へデータを転送するため、データベースとGPU間のデータロードについて意識する必要はありません。また同様に、PL/CUDA関数の戻り値（可変長データ型である場合を含む）もGPU側からCPU側へと書き戻され、SQL関数の戻り値として整形されます。
</span>
</p>

<p>
<div class="figure">
<img src="./figs/plcuda-overview.png">
</div>
</p>

<p>
<span lang="ja">
<code>CREATE FUNCTION</code>構文を用いてPL/CUDA関数を定義すると、この関数の実行時、関数の定義部をそのままGPUのカーネル関数に埋め込んだCUDAプログラムを作成します。
このカーネル関数は、ユーザ定義処理の他に、PL/CUDA関数の引数を参照するための変数の初期化や、実行時エラーをCPU側へ返却するための補助的なコードを含んでいます。また、PG-Stromの実行をサポートするための各種ランタイム関数をインクルードする事もできます。
</span>
</p>

<p>
<span lang="ja">
PL/CUDA関数を用いて作成したネイティブのCUDAプログラムには、特別なメモリ保護などの仕組みはなく、バグのあるPL/CUDA関数の実行により、GPU実行環境や場合によってはPostgreSQL側をクラッシュさせる事も可能です。したがって、PL/CUDA関数の定義はデータベース特権ユーザに限定されています。
</span>
</p>

<p>
<span lang="en">
Below is an example of simple PL/CUDA function.
This function takes two <code>int</code> arguments, then returns the sum of them with <code>int</code> data type.
</span>
<span lang="ja">
以下に単純なPL/CUDA関数の例を示します。
この関数は、<code>int</code>型の引数を二つ取り、その和を<code>int</code>型で返却します。
</span>

<pre>
postgres=# CREATE FUNCTION gpu_add(int, int)
RETURNS int
AS $$
#plcuda_include "cuda_mathlib.h"
#plcuda_begin
  if (get_global_id() == 0)
    *retval = pgfn_int4pl(kcxt, arg1, arg2);
#plcuda_end
$$ LANGUAGE plcuda;
CREATE FUNCTION
</pre>
</p>

<p>
<span lang="ja">
<code>#plcuda_begin</code>と<code>#plcuda_end</code>で囲まれた部分が、PL/CUDA関数の本体部分です。
<code>int</code>型の引数はそれぞれ、<code>pg_int4_t</code>型の変数<code>arg1</code>、<code>arg2</code>として参照する事ができ、<code>pg_int4_t *</code>型のポインタ<code>retval</code>の示す領域にセットしたデータが、PL/CUDA関数の実行結果としてCPU側に返却されます。
<code>pgfn_int4pl()</code>は<code>cuda_mathlib.h</code>で定義されたPG-Stromのランタイム関数の一つで、<code>pg_int4_t</code>同士の加算を実行します。
</span>
</p>

<p>
<span lang="ja">
このPL/CUDA関数を実行すると、以下のように引数である100, 200という整数値をGPU側に送出し、計算結果である300という値をGPUから書き戻しています。通常のSQL関数と同様に、PL/CUDA関数を他のSQL式の一部として使用する事もできます。
</span>

<pre>
postgres=# SELECT gpu_add(100,200);
 gpu_add
---------
     300
(1 row)
</pre>
</p>

<p>
<span lang="ja">
PL/CUDA関数を定義した結果、どのようなカーネル関数が生成されるのかを確認するには<code>plcuda_function_source</code>関数を使用します。
コメント文<tt>code by pl/cuda function</tt>で囲まれたブロックがPL/CUDA関数の定義部から挿入された部分です。
</span>

<pre>
postgres=# SELECT plcuda_function_source('gpu_add'::regproc);
                    plcuda_function_source
---------------------------------------------------------------
 #include "cuda_common.h"                                     +
 #include "cuda_mathlib.h"                                    +
 #include "cuda_plcuda.h"                                     +
                                                              +
 STATIC_INLINE(void)                                          +
 __plcuda_gpu_add_main(kern_plcuda *kplcuda,                  +
               void *workbuf,                                 +
               void *results,                                 +
               kern_context *kcxt)                            +
 {                                                            +
   pg_int4_t *retval __attribute__ ((unused));                +
   pg_int4_t arg1 __attribute__((unused));                    +
   pg_int4_t arg2 __attribute__((unused));                    +
   assert(sizeof(*retval) <= sizeof(kplcuda->__retval));      +
   retval = (pg_int4_t *)kplcuda->__retval;                   +
   arg1 = pg_int4_param(kcxt,0);                              +
   arg2 = pg_int4_param(kcxt,1);                              +
                                                              +
   /* ---- code by pl/cuda function ---- */                   +
   if (get_global_id() == 0)                                  +
     *retval = pgfn_int4pl(kcxt, arg1, arg2);                 +
   /* ---- code by pl/cuda function ---- */                   +
 }                                                            +
                                                              +
 KERNEL_FUNCTION(void)                                        +
 plcuda_gpu_add_main(kern_plcuda *kplcuda,                    +
             void *workbuf,                                   +
             void *results)                                   +
 {                                                            +
   kern_parambuf *kparams = KERN_PLCUDA_PARAMBUF(kplcuda);    +
   kern_context kcxt;                                         +
                                                              +
   assert(kplcuda->nargs == kparams->nparams);                +
   INIT_KERNEL_CONTEXT(&kcxt,plcuda_main_kernel,kparams);     +
   __plcuda_gpu_add_main(kplcuda, workbuf, results, &kcxt);   +
   kern_writeback_error_status(&kplcuda->kerror_main, kcxt.e);+
 }                                                            +
                                                              +

(1 row)
</pre>
</p>

</section>


<section class="manual_2" id="plcuda_structure">
<h2>
<span lang="en">Structure of PL/CUDA</span>
<span lang="ja">PL/CUDAの構造</span>
</h2>

<p>
<span lang="ja">
PL/CUDAの関数定義は、<code>#plcuda_</code>で始まるディレクティブによって分割されるいくつかのコードブロックから構成されます。
このうち、<code>#plcuda_begin</code>より始まるコードブロックのみが必須で、必要に応じてその他のコードブロックを追加する事ができます。
</span>

<pre>
#plcuda_decl
  [...any declarations...]
#plcuda_prep
  [...function body of prep kernel...]
#plcuda_begin
  [...function body of main kernel...]
#plcuda_post
  [...function body of post kernel...]
#plcuda_end
</pre>
</p>

<p>
<span lang="ja">
<code>#plcuda_decl</code>より始まる宣言ブロックは、その他のコードブロックから呼び出す事ができるstatic関数の宣言を記述する事ができます。
他のコードブロックのように、コードブロックの内容が暗黙のうちに特定のカーネル関数に組み込まれる訳ではなく、完全な形式のstatic関数を定義する必要があります。
</span>

<span lang="ja">
GPU上であるカーネル関数がブロックサイズを越える数のスレッドで並列実行されている時、複数の実行ユニット間で同期を取るには、カーネル関数終了のタイミングで待ち合わせる事が唯一の方法です。
例えば、結果バッファが特定の値で初期化されている事を前提としてアルゴリズムが実装されている場合、先ず、結果バッファの初期化を行い、それが全て完了するまではアルゴリズムの中核部分を実行する事はできません。
一部のスレッドが未初期化のバッファに対して実行されるという状況は、容易に不正確な計算結果や実行環境のクラッシュを招いてしまうため、常に避ける必要があります。
</span>
</p>

<p>
<span lang="ja">
<code>#plcuda_prep</code>から始まる前処理ブロック、<code>#plcuda_main</code>から始まる本体ブロック、および<code>#plcuda_post</code>から始まる後処理ブロックは、それぞれユーザ定義のコードブロックの内容が対応するカーネル関数に埋め込まれます。
前処理ブロックと後処理ブロックの定義はオプショナルですが、これらのコードブロックが定義されている時、前処理カーネル関数、本体カーネル関数、後処理カーネル関数の順で実行される事が保証されています。
これらは、本体カーネル関数の実行に先立って結果バッファや作業バッファの初期化を行う事や、本体カーネル関数の実行後に最終結果を集計するなどの用途に使用する事を意図しています。
</span>
</p>

<p>
<span lang="ja">
一個のPL/CUDA関数の呼び出しは、内部的には何個かのSQL関数、GPUカーネル関数の呼び出しを含んでいます。
GPUカーネル関数の呼び出しに先立って、GPUカーネル関数を起動する際のスレッド数、作業バッファや結果バッファのサイズといったパラメータを決定する必要があります。
これらは引数により変動するため、PL/CUDA言語ハンドラは、同じ引数を取る他のSQL関数を呼びだしてこれらのパラメータを決定します。
</span>
</p>

<p>
<span lang="ja">
GPUカーネル関数の呼び出しパラメータが確定すると、次に、PL/CUDA言語ハンドラは、DMAを用いてPL/CUDA関数の引数をGPU上の引数バッファに転送します。
</span>
</p>

<p>
<span lang="ja">
続いて、（定義されていれば）前処理カーネル関数、本体カーネル関数、（定義されていれば）後処理カーネル関数を呼びだします。ブロックサイズを越えたGPUスレッド間で同期を取る方法は、GPUカーネル関数の開始終了のタイミング以外に無い事に留意してください。つまり、作業バッファや結果バッファがある特定の状態を持っている事を期待するのであれば、前処理カーネル関数で初期化を行い、次に本体カーネル関数でこれらのデータ構造を参照する必要があります。
</span>
</p>

<p>
<span lang="ja">
最後に、PL/CUDA言語ハンドラは結果バッファの内容を本体側へ書き戻します。
PL/CUDA関数が固定長のデータを返す場合、GPUカーネル関数がユーザ定義ブロックの開始前に設定する変数<code>retval</code>ポインタの示す領域を更新します。
PL/CUDA関数が可変長のデータを返す場合、<code>retval</code>は<code>pg_varlena_t</code>型の領域を指しており、その値が非NULLである場合には結果バッファ（<code>void *results</code>）への参照でなければいけません。結果バッファ以外の領域を指していたとしても、これは本体側へ書き戻されない事に留意してください。
</span>

<pre>
typedef struct {
    varlena    *value;      /* reference to the results buffer */
    cl_bool     isnull;     /* true, if NULL */
} pg_varlena_t;
</pre>
</p>

<p>
<div class="figure">
<img src="./figs/plcuda-callflow.png">
</div>
</p>

<p>
<span lang="ja">
GPUカーネル関数を実行するスレッド数を指定するには<code>#plcuda_num_threads</code>ディレクティブを使用します。このディレクティブはコードブロックの内側で使用され、定数値またはSQL関数名を指定します。SQL関数は、PL/CUDA関数と同一の引数を持ち<code>bigint</code>型を返すSQL関数として宣言されている必要があります。
</span>

<span lang="ja">
同様に、<code>#plcuda_shmem_unitsz</code>ディレクティブを使用する事で、GPUカーネル関数の実行時に動的に確保する共有メモリのサイズを、スレッドあたりの大きさで指定する事ができます。例えば、スレッドあたり8バイトの共有メモリを使用するGPUカーネル関数が実行ユニットあたり384スレッドで起動された場合、3KBの共有メモリを使用する事ができます。
ここで言う実行ユニットあたりスレッド数は、最適化の結果自動的に算出される値で、<code>#plcuda_num_threads</code>で指定する値とは異なる事に留意してください。
</span>

<span lang="ja">
また、<code>#plcuda_kernel_maxthreads</code>ディレクティブを使用する事で、コードブロックから作成されるカーネル関数の最適化方針を、実行効率最大化から、実行ユニットあたりスレッド数最大化（通常、1024スレッド）へと切り替える事が可能です。実行ユニットあたりのスレッド数が増加する事で、縮約演算など、共有メモリを用いた実行ユニット内部の同期処理を中核とする処理での実行効率向上が期待できます。
</span>

<pre>
#plcuda_num_threads (&lt;value&gt;|&lt;function name&gt;)
#plcuda_shmem_unitsz  (&lt;value&gt;|&lt;function name&gt;)
#plcuda_kernel_maxthreads
</pre>
</p>




</section>

<!--
PostgreSQLでの標準化議論が終わったら、ここに matrix データ型の説明を入れる。
-->


<section class="manual_2" id="plcuda_reference">
<h2>
<span lang="en">PL/CUDA Reference</span>
<span lang="ja">PL/CUDAリファレンス</span>
</h2>

<h3>
<span lang="en">PL/CUDA Directives</span>
<span lang="ja">PL/CUDA ディレクティブ</span>
</h3>

<p>
<span lang="ja">
本節ではPL/CUDA関数で使用する事のできるディレクティブについて説明します。
</span>
</p>

<dl>
<dt><code>#plcuda_begin</code></dt>
<dd>
<p>
<span lang="ja">
本体カーネル関数のコードブロックの開始を宣言します。このディレクティブは必須です。
</span>
<span lang="ja">
GPU上でのコードブロックの実行開始に先立って、PL/CUDA関数の引数は<code>arg1</code>、<code>arg2</code>、...という名前で参照可能となるよう初期化されます。
これらの変数は、PG-StromがSQLデータ型をGPU上で表現するのと同じ方式でセットアップされており、例えば、単精度浮動小数点である<code>real</code>型の引数は、以下のように定義された<code>pg_float4_t</code>型の変数として表現されています。
</span>

<pre>
typedef struct {
    cl_float    value;
    cl_bool     isnull;
} pg_float4_t;
</pre>

<span lang="ja">
これらの変数は各スレッドのプライベート領域に確保されており、変数を更新したとしても次ステップのカーネル関数には反映されません。カーネル関数の終了後、次のカーネル関数に状態を引き継ぐには、<code>void *workbuf</code>ポインタが参照する作業バッファか、<code>void *results</code>ポインタの参照する結果バッファに値を格納する必要があります。
</span>
</p>
</dd>

<dl>
<dt><code>#plcuda_end</code></dt>
<dd>
<span lang="ja">
コードブロックの終了を宣言します。
なお、あるコードブロックの内側で他のコードブロックの開始を宣言した場合、暗黙のうちに<code>#plcuda_end</code>ディレクティブが指定されたものとして扱われます。
</span>
</dd>

<dl>
<dt><code>#plcuda_decl</code></dt>
<dd>
<span lang="ja">
全てのkernel関数の定義に先立って宣言しておくべきコードブロックを記述します。
他のコードブロックとは異なり、自動的にkernel関数として展開される事はありませんので、完全な関数定義を記述する必要があります。
</span>
</dd>

<dl>
<dt><code>#plcuda_prep</code></dt>
<dd>
<span lang="en">
Use of this directive is optional.
</span>
<span lang="ja">
このディレクティブの使用は任意です。
</span>

<span lang="ja">
<code>#plcuda_begin</code>から始まる本体カーネル関数の実行に先立ってGPUで実行すべき、前処理カーネル関数の処理を記述します。
ここでは、結果バッファや作業バッファの初期化を行う事を意図しており、前処理カーネル関数の実行が完了するまでは本体カーネル関数は実行されません。
</span>
<span lang="ja">
PL/CUDA関数の引数へは、本体カーネル関数と同様にアクセスする事ができます。
</span>
</dd>

<dl>
<dt><code>#plcuda_post</code></dt>
<dd>
<span lang="en">
You can optionally use this directive.
</span>
<span lang="ja">
このディレクティブの使用は任意です。
</span>

<span lang="ja">
<code>#plcuda_begin</code>から始まる本体カーネル関数の実行後にGPUで実行すべき、後処理カーネル関数の処理を記述します。
ここでは、CPU側に返却する最終結果を結果バッファにセットする事を意図しており、本体カーネル関数の実行が完了するまでは後処理カーネル関数は実行されません。
</span>
<span lang="ja">
PL/CUDA関数の引数へは、本体カーネル関数と同様にアクセスする事ができます。
</span>
</dd>

<dl>
<dt><code>#plcuda_num_threads (&lt;value&gt;|&lt;function&gt;)</code></dt>
<dd>
<span lang="en">
You can optionally use this directive. If not specified, the default is a constant value <code>0</code>.
</span>
<p>
<span lang="ja">
このディレクティブの使用は任意です。未指定の場合、デフォルト値として定数<code>1</code>が使われます。
</span>
</p>
<p>
<span lang="ja">
このディレクティブが<code>#plcuda_prep</code>、<code>#plcuda_begin</code>、および<code>#plcuda_post</code>コードブロックの内側で指定されると、それぞれのGPUカーネル関数を起動する際のスレッド数を指定する事ができます。
</span>
</p>
<p>
<span lang="ja">
数値が指定されると、PL/CUDAランタイムは指定された数のGPUスレッドを起動してGPUカーネル関数を実行します。
関数名が指定されると、PL/CUDAランタイムは指定されたSQL関数を呼び出し、戻り値で指定された数のGPUスレッドを起動します。このSQL関数は、PL/CUDA関数と同一の引数を取り、<code>bigint</code>型を返す必要があります。
</span>
</p>
</dd>

<dl>
<dt><code>#plcuda_shmem_unitsz (&lt;value&gt;|&lt;function&gt;)</code></dt>
<dd>
<p>
<span lang="en">
Use of this directive is optional. If not specified, the default is a constant value <code>0</code>.
</span>
<span lang="ja">
このディレクティブの使用は任意です。未指定の場合のデフォルト値は定数<code>0</code>です
</span>
</p>
<p>
<span lang="ja">
このディレクティブが<code>#plcuda_prep</code>、<code>#plcuda_begin</code>、および<code>#plcuda_post</code>コードブロックの内側で指定されると、それぞれのGPUカーネル関数を起動する際に動的に確保するスレッドあたり共有メモリのサイズを指定する事ができます。
</span>
</p>
<p>
<span lang="ja">
数値が指定されると、PL/CUDAランタイムは指定された数のGPUスレッドを起動してGPUカーネル関数を実行します。
関数名が指定されると、PL/CUDAランタイムは指定されたSQL関数を呼び出し、戻り値で指定された数のGPUスレッドを起動します。このSQL関数は、PL/CUDA関数と同一の引数を取り、<code>bigint</code>型を返す必要があります。
</span>
</p>
<p>
<span lang="ja">
GPUカーネル関数の実行時に実際に確保される共有メモリのサイズは、本ディレクティブによって指定したスレッドあたり共有メモリのサイズだけでなく、実行ユニットあたりのスレッド数に依存する事に留意してください。（また、実行ユニットあたりのスレッド数は<code>#plcuda_num_threads</code>で指定した値とも異なる概念である事に留意してください。）
例えば、スレッドあたり共有メモリのサイズが8バイトであり、実行ユニットあたりのスレッド数が384である場合、実行ユニット毎に3KBの共有メモリが確保されます。この時、<code>#plcuda_num_threads</code>で指定したスレッド数が32768であれば、このGPUカーネルは86個の実行ユニットを使用して実行されますが、実行ユニットにタスクが投入されるタイミングを決めるのはスケジューラの役割ですので、必ずしも3KB x 86個 = 258KBの共有メモリが一度に消費されるわけではありません。
</span>
</p>
</dd>

<dl>
<dt><code>#plcuda_kernel_maxthreads</code></dt>
<dd>
<p>
<span lang="en">
Use of this directive is optional.
</span>
<span lang="ja">
このディレクティブの使用は任意です。
</span>
</p>
<p>
<span lang="ja">
<code>#plcuda_prep</code>、<code>#plcuda_begin</code>、および<code>#plcuda_post</code>コードブロックの内側でこのディレクティブを指定すると、GPUカーネル関数の最適化ポリシーを『実行効率最適化』から『ブロックあたりスレッド数最大化』に切り替えます。
通常、実行ユニットあたり1024個のスレッドを起動できるようになります。
</span>
</p>
<p>
<span lang="ja">
ブロックあたりスレッド数が多くなると、より多くのスレッドが共有メモリを介して同期処理を行う事ができるようになる半面、スレッドが使用できるレジスタ数が減少するため、一部のローカル変数がグローバルメモリ上に確保されるなど性能面では不利になる事があります。
</span>
</p>
</dd>

<dl>
<dt><code>#plcuda_include "library name"</code></dt>
<dd>
<span lang="ja">
PG-StromのGPUランタイム関数をインクルードし、PL/CUDA関数内で使用できるようにします。
任意のヘッダファイルをインクルードして利用するための機能ではない事に留意してください。
</span>
<dl>
<li>
<code>"cuda_dynpara.h"</code>
<p>
<span lang="ja">
GPU内で動的にカーネル関数を起動するDynamic Parallelism関連のGPUランタイム関数群です。
このファイルをインクルードすると、CUDAのデバイスランタイムも同時にリンクされるようになります。
</span>
</p>
</li>
<li>
<code>"cuda_matrix.h"</code>
<p>
<span lang="ja">
SQLの行列型を処理するためのGPUランタイム関数群です。
なお、現バージョンの行列型はPG-Stromが独自に提供しているものであり、将来バージョンのPostgreSQLが行列型に対応した際に、フォーマットの互換性が維持されない可能性に留意してください。
</span>
</p>
</li>
<li>
<code>"cuda_timelib.h"</code>
<p>
<span lang="ja">
SQLの日付時刻型を処理するためのGPUランタイム関数群です。
</span>
</p>

</li>
<li>
<code>"cuda_textlib.h"</code>
<p>
<span lang="ja">
SQLのテキストデータ型、および<code>LIKE</code>オペレータを処理するためのGPUランタイム関数群です。
</span>
</p>
</li>
<li>
<code>"cuda_numeric.h"</code>
<p>
<span lang="ja">
SQLのNumericデータ型を処理するためのGPUランタイム関数群です。
</span>
</p>
</li>
<li>
<code>"cuda_mathlib.h"</code>
<p>
<span lang="ja">
SQLの数学関数や四則演算オペレータを処理するためのCPUランタイム関数群です。
</span>
</p>
</li>
<li>
<code>"cuda_money.h"</code>
<p>
<span lang="ja">
SQLの通貨型を処理するためのGPUランタイム関数群です。
</span>
</p>
</li>
</dl>
</dd>

<dl>
<dt><code>#plcuda_results_size (&lt;value&gt;|&lt;function&gt;)</code></dt>
<dd>
<p>
<span lang="ja">
このディレクティブの使用は任意です。未指定の場合のデフォルト値は定数<code>0</code>です
</span>
</p>
<p>
<span lang="ja">
PL/CUDA関数の実行時に確保する結果バッファの大きさをバイト単位で指定します。PL/CUDA関数が可変長型データを返却する際には、結果バッファの確保は必須です。
</span>
</p>
<p>
<span lang="ja"<
数値が指定されると、PL/CUDA言語ハンドラは指定されたバイト数のGPU RAMを結果バッファとして確保してからGPUカーネル関数を起動します。
関数名が指定されると、PL/CUDA言語ハンドラは指定されたSQL関数を呼び出し、戻り値で指定されたバイト数のGPU RAMを結果バッファとして確保し、GPUカーネル関数を起動します。このSQL関数は、PL/CUDA関数と同一の引数を取り、<code>bigint</code>型を返す必要があります。
</span>
</p>
<p>
<span lang="ja">
GPUカーネル関数からは、結果バッファは引数<code>void *results</code>で指定された領域としてアクセス可能です。
0バイトが指定された場合、<code>void *results</code>には<code>NULL</code>がセットされます。
</span>
</p>
</dd>

<dl>
<dt><code>#plcuda_working_bufsz (&lt;value&gt;|&lt;function&gt;)</code></dt>
<dd>
<p>
<span lang="ja">
このディレクティブの使用は任意です。未指定の場合のデフォルト値は定数<code>0</code>です
</span>
</p>
<p>
<span lang="ja">
PL/CUDA関数の実行時に確保する作業バッファの大きさをバイト単位で指定します。
</span>
</p>
<p>
<span lang="ja"<
数値が指定されると、PL/CUDA言語ハンドラは指定されたバイト数のGPU RAMを作業バッファとして確保してからGPUカーネル関数を起動します。
関数名が指定されると、PL/CUDA言語ハンドラは指定されたSQL関数を呼び出し、戻り値で指定されたバイト数のGPU RAMを作業バッファとして確保し、GPUカーネル関数を起動します。このSQL関数は、PL/CUDA関数と同一の引数を取り、<code>bigint</code>型を返す必要があります。
</span>
</p>
<p>
<span lang="ja">
GPUカーネル関数からは、作業バッファは引数<code>void *workbuf</code>で指定された領域としてアクセス可能です。
0バイトが指定された場合、<code>void *workbuf</code>には<code>NULL</code>がセットされます。
</span>
</p>
</dd>

<dl>
<dt><code>#plcuda_cpu_fallback &lt;function%gt;</code></dt>
<dd>
<p>
<span lang="ja">
GPUカーネル関数と同等の処理を行うCPUフォールバック関数を指定します。
デフォルトではCPUフォールバック関数は設定されていません。
</span>
</p>
<p>
<span lang="ja">
GPUカーネル関数が<code>StromError_CpuReCheck</code>エラーを返却し、さらにCPUフォールバック関数が設定されていると、PL/CUDA言語ハンドラはGPUでの処理結果を破棄してCPUフォールバック関数を呼びだします。
これは、必ずしも全ての入力に対してGPUカーネル関数を実行可能でない（例えばデータサイズがGPU RAMに載りきらないなど）場合に、代替の救済策を実装するために有用です。ただし、CPUフォールバック関数はシングルスレッドで実行されるため、パフォーマンスが犠牲にならざるを得ない点には留意してください。
</span>
</p>
</dd>
</dl>

<h3>
<span lang="en">
PL/CUDA related functions
</span>
<span lang="ja">
PL/CUDA関連関数
</span>
</h3>
<span lang="ja">
本節ではPL/CUDAに関連するSQL関数について説明します。
</span>
<dt>
<code>text plcuda_function_source(regproc)</code>
</dt>
<dd>
<p>
<span lang="ja">
引数としてPL/CUDA関数のOIDを与えると、PL/CUDA関数から生成されるGPUカーネルのソースコードを出力します。
</span>
</p>
</dd>
</dl>

</section>

<!--
アドバンスドな使い方。Dynamic Parallelismを使って繰り返し処理を実装する方法など。
-->

</article>
